<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture: 16 üîñ Predictions with rpart | bookdemo.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture: 16 üîñ Predictions with rpart | bookdemo.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture: 16 üîñ Predictions with rpart | bookdemo.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="P1.html"/>
<link rel="next" href="lr.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/font-awesome-5.15.3/css/all.min.css" rel="stylesheet" />
<link href="libs/font-awesome-5.15.3/css/v4-shims.min.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DATA 101 Book</a>
<a href="https://github.com/dev7796/data101_tutorial" target="blank">Github Source</a>
<a href="https://b.socrative.com/teacher/#launch" target="blank">Socrative Quiz</a>
<a href="https://dev7796.shinyapps.io/testing_button/" target="black">Question Roulette</a>
<a href="https://dev7796.shinyapps.io/box_shiny/" target="black">Quiz Code</a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="2" data-path="b2022.html"><a href="b2022.html"><i class="fa fa-check"></i><b>2</b> üîñ Best Works of 2022<span></span></a></li>
<li class="chapter" data-level="3" data-path="setting-up-r.html"><a href="setting-up-r.html"><i class="fa fa-check"></i><b>3</b> Setting Up R<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="setting-up-r.html"><a href="setting-up-r.html#setting"><i class="fa fa-check"></i><b>3.1</b> Create New Project<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="setting-up-r.html"><a href="setting-up-r.html#how-to-upload-a-data-set"><i class="fa fa-check"></i><b>3.2</b> How to upload a data set?<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="setting-up-r.html"><a href="setting-up-r.html#saving-your-work"><i class="fa fa-check"></i><b>3.3</b> Saving your work<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="setting-up-r.html"><a href="setting-up-r.html#general-r-references"><i class="fa fa-check"></i><b>3.4</b> General R References<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="setting-up-r.html"><a href="setting-up-r.html#textbook-concepts"><i class="fa fa-check"></i><b>3.5</b> Textbook Concepts<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="setting-up-r.html"><a href="setting-up-r.html#r-functions-used-in-this-class"><i class="fa fa-check"></i><b>3.6</b> R functions used in this class<span></span></a></li>
<li class="chapter" data-level="3.7" data-path="setting-up-r.html"><a href="setting-up-r.html#data-sets"><i class="fa fa-check"></i><b>3.7</b> Data sets<span></span></a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="setting-up-r.html"><a href="setting-up-r.html#moody"><i class="fa fa-check"></i><b>3.7.1</b> Moody<span></span></a></li>
<li class="chapter" data-level="3.7.2" data-path="setting-up-r.html"><a href="setting-up-r.html#movies"><i class="fa fa-check"></i><b>3.7.2</b> Movies<span></span></a></li>
<li class="chapter" data-level="3.7.3" data-path="setting-up-r.html"><a href="setting-up-r.html#traffic"><i class="fa fa-check"></i><b>3.7.3</b> Traffic<span></span></a></li>
<li class="chapter" data-level="3.7.4" data-path="setting-up-r.html"><a href="setting-up-r.html#hindex"><i class="fa fa-check"></i><b>3.7.4</b> Hindex<span></span></a></li>
<li class="chapter" data-level="3.7.5" data-path="setting-up-r.html"><a href="setting-up-r.html#prediction-1-dataset"><i class="fa fa-check"></i><b>3.7.5</b> Prediction 1 Dataset<span></span></a></li>
<li class="chapter" data-level="3.7.6" data-path="setting-up-r.html"><a href="setting-up-r.html#midterm-project-and-final-exam-distribution-in-prof.-moody-class"><i class="fa fa-check"></i><b>3.7.6</b> Midterm, Project and Final Exam distribution in Prof.¬†Moody class<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plots.html"><a href="plots.html"><i class="fa fa-check"></i><b>4</b> üîñ Plots<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="plots.html"><a href="plots.html#vector"><i class="fa fa-check"></i><b>4.1</b> Vector<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="plots.html"><a href="plots.html#snippet-1"><i class="fa fa-check"></i><b>4.1.1</b> Snippet 1<span></span></a></li>
<li class="chapter" data-level="4.1.2" data-path="plots.html"><a href="plots.html#snippet-2"><i class="fa fa-check"></i><b>4.1.2</b> Snippet 2<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="plots.html"><a href="plots.html#data-frames"><i class="fa fa-check"></i><b>4.2</b> Data Frames<span></span></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="plots.html"><a href="plots.html#snippet-1-1"><i class="fa fa-check"></i><b>4.2.1</b> Snippet 1<span></span></a></li>
<li class="chapter" data-level="4.2.2" data-path="plots.html"><a href="plots.html#snippet-2-1"><i class="fa fa-check"></i><b>4.2.2</b> Snippet 2<span></span></a></li>
<li class="chapter" data-level="4.2.3" data-path="plots.html"><a href="plots.html#snippet-3"><i class="fa fa-check"></i><b>4.2.3</b> Snippet 3<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="plots.html"><a href="plots.html#table"><i class="fa fa-check"></i><b>4.3</b> Table<span></span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="plots.html"><a href="plots.html#snippet-1-2"><i class="fa fa-check"></i><b>4.3.1</b> Snippet 1<span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="plots.html"><a href="plots.html#code-review"><i class="fa fa-check"></i><b>4.3.2</b> Code Review<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="plots.html"><a href="plots.html#scartterplot"><i class="fa fa-check"></i><b>4.4</b> Scatter Plot<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="plots.html"><a href="plots.html#barplot"><i class="fa fa-check"></i><b>4.5</b> Bar Plot<span></span></a></li>
<li class="chapter" data-level="4.6" data-path="plots.html"><a href="plots.html#boxplot"><i class="fa fa-check"></i><b>4.6</b> Box Plot<span></span></a></li>
<li class="chapter" data-level="4.7" data-path="plots.html"><a href="plots.html#mosaicplot"><i class="fa fa-check"></i><b>4.7</b> Mosaic Plot<span></span></a></li>
<li class="chapter" data-level="4.8" data-path="plots.html"><a href="plots.html#additional-references"><i class="fa fa-check"></i><b>4.8</b> Additional References<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-transformation.html"><a href="data-transformation.html"><i class="fa fa-check"></i><b>5</b> üîñ Data Transformation<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-transformation.html"><a href="data-transformation.html#basic-functions"><i class="fa fa-check"></i><b>5.1</b> Basic Functions<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="data-transformation.html"><a href="data-transformation.html#mean"><i class="fa fa-check"></i><b>5.1.1</b> mean()<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="data-transformation.html"><a href="data-transformation.html#length"><i class="fa fa-check"></i><b>5.1.2</b> length()<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="data-transformation.html"><a href="data-transformation.html#max"><i class="fa fa-check"></i><b>5.1.3</b> max()<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="data-transformation.html"><a href="data-transformation.html#min"><i class="fa fa-check"></i><b>5.1.4</b> min()<span></span></a></li>
<li class="chapter" data-level="5.1.5" data-path="data-transformation.html"><a href="data-transformation.html#sd"><i class="fa fa-check"></i><b>5.1.5</b> sd()<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-transformation.html"><a href="data-transformation.html#subset"><i class="fa fa-check"></i><b>5.2</b> Subset<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="data-transformation.html"><a href="data-transformation.html#nrow"><i class="fa fa-check"></i><b>5.2.1</b> Snippet 1- example of subset function<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="data-transformation.html"><a href="data-transformation.html#snippet-2--example-of-subset-function"><i class="fa fa-check"></i><b>5.2.2</b> Snippet 2- example of subset function<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="data-transformation.html"><a href="data-transformation.html#snippet-3--subset-as-subframe"><i class="fa fa-check"></i><b>5.2.3</b> Snippet 3- subset as subframe<span></span></a></li>
<li class="chapter" data-level="5.2.4" data-path="data-transformation.html"><a href="data-transformation.html#snippet-4--subsetting-columns"><i class="fa fa-check"></i><b>5.2.4</b> Snippet 4- subsetting columns<span></span></a></li>
<li class="chapter" data-level="5.2.5" data-path="data-transformation.html"><a href="data-transformation.html#snippet-5--sub-setting-rows-and-columns"><i class="fa fa-check"></i><b>5.2.5</b> Snippet 5- sub-setting rows and columns<span></span></a></li>
<li class="chapter" data-level="5.2.6" data-path="data-transformation.html"><a href="data-transformation.html#code-review-1"><i class="fa fa-check"></i><b>5.2.6</b> Code Review<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="data-transformation.html"><a href="data-transformation.html#tapply"><i class="fa fa-check"></i><b>5.3</b> tapply<span></span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-transformation.html"><a href="data-transformation.html#snippet-1--example-of-tapply-followed-by-barplot"><i class="fa fa-check"></i><b>5.3.1</b> Snippet 1- Example of tapply followed by barplot<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="data-transformation.html"><a href="data-transformation.html#code-review-2"><i class="fa fa-check"></i><b>5.3.2</b> Code Review<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-transformation.html"><a href="data-transformation.html#derived-attribute"><i class="fa fa-check"></i><b>5.4</b> Derived Attribute<span></span></a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-transformation.html"><a href="data-transformation.html#snippet-1---making-new-categorical-attribute."><i class="fa fa-check"></i><b>5.4.1</b> Snippet 1 - Making new categorical attribute.<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="data-transformation.html"><a href="data-transformation.html#cut"><i class="fa fa-check"></i><b>5.4.2</b> Cut<span></span></a></li>
<li class="chapter" data-level="5.4.3" data-path="data-transformation.html"><a href="data-transformation.html#code-review-3"><i class="fa fa-check"></i><b>5.4.3</b> Code Review<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html"><i class="fa fa-check"></i><b>6</b> üîñ Free Style: Data Exploration<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#moody-data-puzzle"><i class="fa fa-check"></i><b>6.1</b> Moody Data Puzzle<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#moody-data-puzzle---pattern-i-injected"><i class="fa fa-check"></i><b>6.1.1</b> Moody Data Puzzle - Pattern I Injected<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#best-students-submissions-2022"><i class="fa fa-check"></i><b>6.1.2</b> Best Student‚Äôs Submissions 2022<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#movies-data-hunt"><i class="fa fa-check"></i><b>6.2</b> Movies Data Hunt<span></span></a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#movies-data-puzzle---pattern-i-injected"><i class="fa fa-check"></i><b>6.2.1</b> Movies Data Puzzle - Pattern I Injected<span></span></a></li>
<li class="chapter" data-level="6.2.2" data-path="free-style-data-exploration.html"><a href="free-style-data-exploration.html#best-students-submissions-2022-1"><i class="fa fa-check"></i><b>6.2.2</b> Best Student‚Äôs Submissions 2022<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ztest.html"><a href="ztest.html"><i class="fa fa-check"></i><b>7</b> üîñ Hypothesis Testing: z-test<span></span></a>
<ul>
<li class="chapter" data-level="7.1" data-path="ztest.html"><a href="ztest.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="7.2" data-path="ztest.html"><a href="ztest.html#pnorm"><i class="fa fa-check"></i><b>7.2</b> Snippet 1: Shows the code for z-test to test the following hypotheses<span></span></a></li>
<li class="chapter" data-level="7.3" data-path="ztest.html"><a href="ztest.html#snippet-2-make-your-own-data-and-see-how-p-value-changes"><i class="fa fa-check"></i><b>7.3</b> Snippet 2: Make your own data and see how p-value changes<span></span></a></li>
<li class="chapter" data-level="7.4" data-path="ztest.html"><a href="ztest.html#additional-references-1"><i class="fa fa-check"></i><b>7.4</b> Additional References<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptest.html"><a href="ptest.html"><i class="fa fa-check"></i><b>8</b> üîñ Hypothesis Testing: Permutation Test<span></span></a>
<ul>
<li class="chapter" data-level="8.1" data-path="ptest.html"><a href="ptest.html#snippet-1-4"><i class="fa fa-check"></i><b>8.1</b> Snippet 1<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="ptest.html"><a href="ptest.html#snippet-2-2"><i class="fa fa-check"></i><b>8.2</b> Snippet 2<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="ptest.html"><a href="ptest.html#snippet-3-1"><i class="fa fa-check"></i><b>8.3</b> Snippet 3<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chitest.html"><a href="chitest.html"><i class="fa fa-check"></i><b>9</b> üîñ Chi Square Analysis<span></span></a>
<ul>
<li class="chapter" data-level="9.1" data-path="chitest.html"><a href="chitest.html#snippet-1-5"><i class="fa fa-check"></i><b>9.1</b> Snippet 1<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="chitest.html"><a href="chitest.html#snippet-2-3"><i class="fa fa-check"></i><b>9.2</b> Snippet 2<span></span></a></li>
<li class="chapter" data-level="9.3" data-path="chitest.html"><a href="chitest.html#snippet-3-2"><i class="fa fa-check"></i><b>9.3</b> Snippet 3<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="Mtest.html"><a href="Mtest.html"><i class="fa fa-check"></i><b>10</b> üîñ Multiple Hypothesis Testing<span></span></a>
<ul>
<li class="chapter" data-level="10.1" data-path="Mtest.html"><a href="Mtest.html#snippet-1---benjamini-hochberg-algorithm"><i class="fa fa-check"></i><b>10.1</b> Snippet 1 - Benjamini-Hochberg Algorithm<span></span></a></li>
<li class="chapter" data-level="10.2" data-path="Mtest.html"><a href="Mtest.html#snippet-2-4"><i class="fa fa-check"></i><b>10.2</b> Snippet 2<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="Mtest.html"><a href="Mtest.html#additional-references-2"><i class="fa fa-check"></i><b>10.3</b> Additional References<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="cr.html"><a href="cr.html"><i class="fa fa-check"></i><b>11</b> Code Review: Exploratory Queries in R<span></span></a>
<ul>
<li class="chapter" data-level="11.1" data-path="cr.html"><a href="cr.html#movies-dataset-example"><i class="fa fa-check"></i><b>11.1</b> Movies Dataset Example<span></span></a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="cr.html"><a href="cr.html#snippet-1-what-is-the-mean-imdb-of-low-budget-comedies"><i class="fa fa-check"></i><b>11.1.1</b> Snippet 1: What is the mean imdb of low budget comedies?<span></span></a></li>
<li class="chapter" data-level="11.1.2" data-path="cr.html"><a href="cr.html#snippet-2-what-is-standard-deviation-of-imdb-score-of-high-gross-family-movies"><i class="fa fa-check"></i><b>11.1.2</b> Snippet 2: What is standard deviation of imdb score of high gross Family movies?<span></span></a></li>
<li class="chapter" data-level="11.1.3" data-path="cr.html"><a href="cr.html#snippet-3-what-is-the-lowest-imdb-score-among-high-budget-movies"><i class="fa fa-check"></i><b>11.1.3</b> Snippet 3: What is the lowest imdb score among high budget movies?<span></span></a></li>
<li class="chapter" data-level="11.1.4" data-path="cr.html"><a href="cr.html#snippet-4-how-many-low-budget-movies-generated-high-gross-income"><i class="fa fa-check"></i><b>11.1.4</b> Snippet 4: How many low budget movies generated high gross income?<span></span></a></li>
<li class="chapter" data-level="11.1.5" data-path="cr.html"><a href="cr.html#snippet-5-what-is-imdb-score-of-the-first-non-us-movie-in-the-movies-data-frame"><i class="fa fa-check"></i><b>11.1.5</b> Snippet 5: What is imdb score of the first non-US movie in the movies data frame?<span></span></a></li>
<li class="chapter" data-level="11.1.6" data-path="cr.html"><a href="cr.html#snippet-6-what-is-the-least-frequent-genre-among-uk-movies"><i class="fa fa-check"></i><b>11.1.6</b> Snippet 6: What is the least frequent genre among UK movies?<span></span></a></li>
<li class="chapter" data-level="11.1.7" data-path="cr.html"><a href="cr.html#snippet-7-which-content-rating-has-the-lowest-average-imdb-score"><i class="fa fa-check"></i><b>11.1.7</b> Snippet 7: Which content rating has the lowest average imdb score?<span></span></a></li>
<li class="chapter" data-level="11.1.8" data-path="cr.html"><a href="cr.html#snippet-8-movies-from-which-country-have-the-smallest-average-imdb-score"><i class="fa fa-check"></i><b>11.1.8</b> Snippet 8: Movies from which country have the smallest average imdb score?<span></span></a></li>
<li class="chapter" data-level="11.1.9" data-path="cr.html"><a href="cr.html#snippet-9-what-is-the-least-frequent-genre-in-movies-data-frame"><i class="fa fa-check"></i><b>11.1.9</b> Snippet 9: What is the least frequent genre in movies data frame?<span></span></a></li>
<li class="chapter" data-level="11.1.10" data-path="cr.html"><a href="cr.html#snippet-10-z-value-2.4-whats-the-p-value"><i class="fa fa-check"></i><b>11.1.10</b> Snippet 10: z value = 2.4, whats the p-value?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="cr.html"><a href="cr.html#census-dataset-example"><i class="fa fa-check"></i><b>11.2</b> Census Dataset Example<span></span></a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="cr.html"><a href="cr.html#snippet-11-for-the-individual-over-50-which-profession-has-the-highest-average-capital-gain"><i class="fa fa-check"></i><b>11.2.1</b> Snippet 11: For the individual over 50, which profession has the highest average capital gain?<span></span></a></li>
<li class="chapter" data-level="11.2.2" data-path="cr.html"><a href="cr.html#snippet-12-which-profession-has-the-highest-average-capital-gains-sales-or-tech-support"><i class="fa fa-check"></i><b>11.2.2</b> Snippet 12: Which profession has the highest average capital gains; Sales or Tech-support?<span></span></a></li>
<li class="chapter" data-level="11.2.3" data-path="cr.html"><a href="cr.html#snippet-13-what-is-most-frequent-profession-of-people-with-less-than-10-years-od-of-education"><i class="fa fa-check"></i><b>11.2.3</b> Snippet 13: What is most frequent profession of people with less than 10 years od of education?<span></span></a></li>
<li class="chapter" data-level="11.2.4" data-path="cr.html"><a href="cr.html#snippet-14-what-is-minimum-number-of-years-of-education-for-people-with-exec-managerial-specialty"><i class="fa fa-check"></i><b>11.2.4</b> Snippet 14: What is minimum number of years of education for people with Exec-managerial specialty?<span></span></a></li>
<li class="chapter" data-level="11.2.5" data-path="cr.html"><a href="cr.html#snippet-15-what-is-the-most-frequent-degree-for-natives-of-the-united-states"><i class="fa fa-check"></i><b>11.2.5</b> Snippet 15: What is the most frequent degree for natives of the United States?<span></span></a></li>
<li class="chapter" data-level="11.2.6" data-path="cr.html"><a href="cr.html#snippet-16-what-is-the-least-frequent-degree-for-people-with-at-least-12-years-of-education"><i class="fa fa-check"></i><b>11.2.6</b> Snippet 16: What is the least frequent degree for people with at least 12 years of education?<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="common.html"><a href="common.html"><i class="fa fa-check"></i><b>12</b> üîñ Common Sense Judgement and Probability<span></span></a></li>
<li class="chapter" data-level="13" data-path="br.html"><a href="br.html"><i class="fa fa-check"></i><b>13</b> üîñ Bayesian Reasoning<span></span></a>
<ul>
<li class="chapter" data-level="13.1" data-path="br.html"><a href="br.html#snippet-1-covid-odds-after-positive-home-test."><i class="fa fa-check"></i><b>13.1</b> Snippet 1: Covid Odds after positive Home Test.<span></span></a></li>
<li class="chapter" data-level="13.2" data-path="br.html"><a href="br.html#snippet-2-what-are-the-odds-that-an-f-student-is-a-freshman"><i class="fa fa-check"></i><b>13.2</b> Snippet 2: What are the odds that an ‚ÄòF‚Äô student is a freshman?<span></span></a></li>
<li class="chapter" data-level="13.3" data-path="br.html"><a href="br.html#snippet-3-what-are-the-odds-that-a-a-student-with-the-score-less-than-80-is-a-psychology-major"><i class="fa fa-check"></i><b>13.3</b> Snippet 3: What are the odds that a ‚ÄòA‚Äô student with the score less than 80 is a psychology major?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Pc1.html"><a href="Pc1.html"><i class="fa fa-check"></i><b>14</b> üîñ Prediction Challenges<span></span></a>
<ul>
<li class="chapter" data-level="14.1" data-path="Pc1.html"><a href="Pc1.html#general-structure-of-the-prediction-challenges"><i class="fa fa-check"></i><b>14.1</b> General Structure of the Prediction Challenges<span></span></a></li>
<li class="chapter" data-level="14.2" data-path="Pc1.html"><a href="Pc1.html#challenge-1---freestyle-prediction-of-grades-in-yet-another-moody-data-set"><i class="fa fa-check"></i><b>14.2</b> Challenge 1 - Freestyle prediction of grades in yet another MOODY data set<span></span></a></li>
<li class="chapter" data-level="14.3" data-path="Pc1.html"><a href="Pc1.html#this-is-how-an-a-in-this-course-looks-like"><i class="fa fa-check"></i><b>14.3</b> This is how an ‚ÄòA‚Äô in this course looks like<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="P1.html"><a href="P1.html"><i class="fa fa-check"></i><b>15</b> üîñ Free Style: Prediction<span></span></a>
<ul>
<li class="chapter" data-level="15.1" data-path="P1.html"><a href="P1.html#snippet-1-example-of-a-simple-freestyle-prediction-model"><i class="fa fa-check"></i><b>15.1</b> Snippet 1: Example of a simple freestyle prediction model<span></span></a></li>
<li class="chapter" data-level="15.2" data-path="P1.html"><a href="P1.html#snippet-2-how-to-build-a-freestyle-your-own-code-prediction-model"><i class="fa fa-check"></i><b>15.2</b> Snippet 2: How to build a freestyle (your own code) prediction model?<span></span></a></li>
<li class="chapter" data-level="15.3" data-path="P1.html"><a href="P1.html#snippet-3-one-step-crossvalidation"><i class="fa fa-check"></i><b>15.3</b> Snippet 3: One-step crossvalidation<span></span></a></li>
<li class="chapter" data-level="15.4" data-path="P1.html"><a href="P1.html#snippet-4-preparing-submission.csv-for-kaggle"><i class="fa fa-check"></i><b>15.4</b> Snippet 4: Preparing submission.csv for Kaggle<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="prpart.html"><a href="prpart.html"><i class="fa fa-check"></i><b>16</b> üîñ Predictions with rpart<span></span></a>
<ul>
<li class="chapter" data-level="16.1" data-path="prpart.html"><a href="prpart.html#rpart"><i class="fa fa-check"></i><b>16.1</b> Use of Rpart<span></span></a></li>
<li class="chapter" data-level="16.2" data-path="prpart.html"><a href="prpart.html#rpartplot"><i class="fa fa-check"></i><b>16.2</b> Visualize the Decision tree<span></span></a></li>
<li class="chapter" data-level="16.3" data-path="prpart.html"><a href="prpart.html#rpartcontrol"><i class="fa fa-check"></i><b>16.3</b> Rpart Control<span></span></a></li>
<li class="chapter" data-level="16.4" data-path="prpart.html"><a href="prpart.html#rpartpredict"><i class="fa fa-check"></i><b>16.4</b> Prediction using rpart.<span></span></a></li>
<li class="chapter" data-level="16.5" data-path="prpart.html"><a href="prpart.html#splitdata"><i class="fa fa-check"></i><b>16.5</b> Split the data yourself.<span></span></a></li>
<li class="chapter" data-level="16.6" data-path="prpart.html"><a href="prpart.html#crossvalidation"><i class="fa fa-check"></i><b>16.6</b> Cross Validation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="lr.html"><a href="lr.html"><i class="fa fa-check"></i><b>17</b> üîñ Linear Regression<span></span></a>
<ul>
<li class="chapter" data-level="17.1" data-path="lr.html"><a href="lr.html#snippet-1-how-much-do-midterm-project-and-final-exam-count"><i class="fa fa-check"></i><b>17.1</b> Snippet 1: How much do Midterm, Project and Final Exam count?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="MLP.html"><a href="MLP.html"><i class="fa fa-check"></i><b>18</b> üîñ Machine Learning-Prediction Loop<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prpart" class="section level1 hasAnchor" number="16">
<h1><span class="header-section-number">Lecture: 16</span> üîñ Predictions with rpart<a href="prpart.html#prpart" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<script src="files/js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"> </script>
<ul>
<li><strong>Lecture slides: </strong> <button class="btn btn-primary" data-toggle="collapse" data-target="#dt12">Decision Trees </button>
<div id="dt12" class="collapse">
<embed src="https://docs.google.com/presentation/d/1Yw11iu0FnUbiNKrwEKyWHxZ1oXUVG0APfI9acEbB91o/edit?usp=sharing" width="100%" height="500px">
</embed>
</div></li>
</ul>
<p>Decision trees are one of the most powerful and popular tools for classification and prediction. The reason decision trees are very popular is that they can generate rules which are easier to understand as compared to other models. They require much less computations for performing modeling and prediction. Both continuous/numerical and categorical variables are handled easily while creating the decision trees.</p>
<div id="rpart" class="section level2 hasAnchor" number="16.1">
<h2><span class="header-section-number">16.1</span> Use of Rpart<a href="prpart.html#rpart" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recursive Partitioning and Regression Tree <code>RPART</code> library is a collection of routines which implement Classification and Regression Tree (CART) which is a type of Decision Tree.The resulting model can be represented as a binary tree.</p>
<p>The library associated with this <code>RPART</code> is called <code>rpart</code>. Install this library using <code>install.packages("rpart")</code>.</p>
<p>Syntax for building the decision tree using rpart():</p>
<ul>
<li><code>rpart( formula , method, data, control,...)</code>
<ul>
<li><em>formula</em>: here we mention the prediction column and the other related columns(predictors) on which the prediction will be based on.
<ul>
<li><code>prediction ~ predictor1 + predictor2 + predictor3 + ...</code></li>
</ul></li>
<li><em>method</em>: here we describe the type of decision tree we want. If nothing is provided, the function makes an intelligent guess. We can use ‚Äúanova‚Äù for regression, ‚Äúclass‚Äù for classification, etc.</li>
<li><em>data</em>: here we provide the dataset on which we want to fit the decision tree on.</li>
<li><em>control</em>: here we provide the control parameters for the decision tree. Explained more in detail in the section further in this chapter.</li>
</ul></li>
</ul>
<p>For more info on the rpart function visit <a href="https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart">rpart documentation</a></p>
<p>Lets look at an example on the Moody 2022 dataset.</p>
<ul>
<li>We will use the rpart() function with the following inputs:
<ul>
<li>prediction -&gt; GRADE</li>
<li>predictors -&gt; SCORE, DOZES_OFF, TEXTING_IN_CLASS, PARTICIPATION</li>
<li>data -&gt; moody dataset</li>
<li>method -&gt; ‚Äúclass‚Äù for classification.</li>
</ul></li>
</ul>
<p>dc_light_exercise_unnamed-chunk-123</p>
<pre><code>## Warning: package &#39;rpart&#39; was built under R version 4.1.2</code></pre>
<pre><code>## n= 828 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 828 642 D (0.19 0.18 0.19 0.22 0.21)  
##     2) SCORE&gt;=80.025 176  16 A (0.91 0.091 0 0 0) *
##     3) SCORE&lt; 80.025 652 466 D (0 0.21 0.25 0.29 0.26)  
##       6) SCORE&gt;=29.545 475 307 D (0 0.28 0.34 0.35 0.025)  
##        12) SCORE&gt;=51.455 256 122 B (0 0.52 0.46 0.016 0)  
##          24) SCORE&gt;=59.15 181  49 B (0 0.73 0.27 0 0)  
##            48) PARTICIPATION&gt;=0.505 69   0 B (0 1 0 0 0) *
##            49) PARTICIPATION&lt; 0.505 112  49 B (0 0.56 0.44 0 0)  
##              98) SCORE&gt;=67.33 46   5 B (0 0.89 0.11 0 0) *
##              99) SCORE&lt; 67.33 66  22 C (0 0.33 0.67 0 0)  
##               198) PARTICIPATION&lt; 0.155 31  12 B (0 0.61 0.39 0 0) *
##               199) PARTICIPATION&gt;=0.155 35   3 C (0 0.086 0.91 0 0) *
##          25) SCORE&lt; 59.15 75   6 C (0 0.027 0.92 0.053 0) *
##        13) SCORE&lt; 51.455 219  55 D (0 0 0.2 0.75 0.055)  
##          26) SCORE&gt;=42.935 93  42 D (0 0 0.45 0.55 0)  
##            52) PARTICIPATION&gt;=0.65 21   0 C (0 0 1 0 0) *
##            53) PARTICIPATION&lt; 0.65 72  21 D (0 0 0.29 0.71 0)  
##             106) DOZES_OFF=sometimes 37  16 C (0 0 0.57 0.43 0)  
##               212) TEXTING_IN_CLASS=never,rarely 27   6 C (0 0 0.78 0.22 0) *
##               213) TEXTING_IN_CLASS=always 10   0 D (0 0 0 1 0) *
##             107) DOZES_OFF=always,never 35   0 D (0 0 0 1 0) *
##          27) SCORE&lt; 42.935 126  13 D (0 0 0.0079 0.9 0.095) *
##       7) SCORE&lt; 29.545 177  18 F (0 0 0 0.1 0.9) *</code></pre>
<p>We can see that the output of the rpart() function is the decision tree with details of,</p>
<ul>
<li>node -&gt; node number</li>
<li>split -&gt; split conditions/tests</li>
<li>n -&gt; number of records in either branch i.e.¬†subset</li>
<li>yval -&gt; output value i.e.¬†the target predicted value.</li>
<li>yprob -&gt; probability of obtaining a particular category as the predicted output.</li>
</ul>
<p>Using the output tree, we can use the predict function to predict the grades of the test data. We will look at this process later in section <a href="prpart.html#rpartpredict">16.4</a></p>
<p>But coming back to the output of the rpart() function, the text type output is useful but difficult to read and understand, right! We will look at visualizing the decision tree in the next section.</p>
<hr />
</div>
<div id="rpartplot" class="section level2 hasAnchor" number="16.2">
<h2><span class="header-section-number">16.2</span> Visualize the Decision tree<a href="prpart.html#rpartplot" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To visualize and understand the rpart() tree output in the easiest way possible, we use a library called <code>rpart.plot</code>. The function <code>rpart.plot()</code> of the rpart.plot library is the function used to visualize decision trees.</p>
<p>The <code>rpart.plot</code> library is a front-end wrapper to the library <code>prp</code> which is the most basic library for plotting decision trees. <code>prp</code> allows various aesthetic modifications for visualizing the decision tree. We will look at a few examples of using <code>prp</code> below.</p>
<p>But, first lets look at a example to visualize the output decision tree in the previous example on Moody dataset using <code>rpart.plot()</code></p>
<p><em>NOTE</em>: The online runnable code block does not support <code>rpart.plot and prp</code> library and functions, thus the output of the following code examples are provided directly.</p>
<p>dc_light_exercise_unnamed-chunk-124</p>
<pre><code>## n= 828 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 828 642 D (0.19 0.18 0.19 0.22 0.21)  
##     2) SCORE&gt;=80.025 176  16 A (0.91 0.091 0 0 0) *
##     3) SCORE&lt; 80.025 652 466 D (0 0.21 0.25 0.29 0.26)  
##       6) SCORE&gt;=29.545 475 307 D (0 0.28 0.34 0.35 0.025)  
##        12) SCORE&gt;=51.455 256 122 B (0 0.52 0.46 0.016 0)  
##          24) SCORE&gt;=59.15 181  49 B (0 0.73 0.27 0 0)  
##            48) PARTICIPATION&gt;=0.505 69   0 B (0 1 0 0 0) *
##            49) PARTICIPATION&lt; 0.505 112  49 B (0 0.56 0.44 0 0)  
##              98) SCORE&gt;=67.33 46   5 B (0 0.89 0.11 0 0) *
##              99) SCORE&lt; 67.33 66  22 C (0 0.33 0.67 0 0)  
##               198) PARTICIPATION&lt; 0.155 31  12 B (0 0.61 0.39 0 0) *
##               199) PARTICIPATION&gt;=0.155 35   3 C (0 0.086 0.91 0 0) *
##          25) SCORE&lt; 59.15 75   6 C (0 0.027 0.92 0.053 0) *
##        13) SCORE&lt; 51.455 219  55 D (0 0 0.2 0.75 0.055)  
##          26) SCORE&gt;=42.935 93  42 D (0 0 0.45 0.55 0)  
##            52) PARTICIPATION&gt;=0.65 21   0 C (0 0 1 0 0) *
##            53) PARTICIPATION&lt; 0.65 72  21 D (0 0 0.29 0.71 0)  
##             106) DOZES_OFF=sometimes 37  16 C (0 0 0.57 0.43 0)  
##               212) TEXTING_IN_CLASS=never,rarely 27   6 C (0 0 0.78 0.22 0) *
##               213) TEXTING_IN_CLASS=always 10   0 D (0 0 0 1 0) *
##             107) DOZES_OFF=always,never 35   0 D (0 0 0 1 0) *
##          27) SCORE&lt; 42.935 126  13 D (0 0 0.0079 0.9 0.095) *
##       7) SCORE&lt; 29.545 177  18 F (0 0 0 0.1 0.9) *</code></pre>
<p><img src="bookdemo_files/figure-html/unnamed-chunk-124-1.png" width="672" />
<img src="https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/img/modeling/2022dt.png" alt="Output Plot of rpart.plot() function" /></p>
<p>We can see that after plotting the tree using rpart.plot() function, the tree is more readable and provides better information about the splitting conditions, and the probability of outcomes. Each leaf node has information about</p>
<ul>
<li>the grade category.</li>
<li>the outcome probability of each grade category.</li>
<li>the records percentage out of total records.</li>
</ul>
<p>To study more in detail the arguments that can be passed to the rpart.plot() function, please look at these guides <a href="https://www.rdocumentation.org/packages/rpart.plot/versions/3.0.9/topics/rpart.plot">rpart.plot</a> and <a href="http://www.milbo.org/doc/prp.pdf">Plotting with rpart.plot (PDF)</a></p>
<p>Note that for any beginner using rpart.plot() function is the easiest way. But if you want to learn another way of plotting rpart trees then the following function can be used.</p>
<p>So,another form of plotting rpart trees in a very minimalistic way is using the <code>plot rpart i.e. prp()</code> function, which is actually the working function behind rpart.plot().</p>
<p>Lets look at a same example like above but using prp().</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="prpart.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First lets import the rpart library</span></span>
<span id="cb5-2"><a href="prpart.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb5-3"><a href="prpart.html#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="prpart.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Import dataset</span></span>
<span id="cb5-5"><a href="prpart.html#cb5-5" aria-hidden="true" tabindex="-1"></a>moody <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/dataset/MOODY-2019.csv&quot;</span>)</span>
<span id="cb5-6"><a href="prpart.html#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="prpart.html#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use of the rpart() function.</span></span>
<span id="cb5-8"><a href="prpart.html#cb5-8" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(GRADE <span class="sc">~</span> SCORE<span class="sc">+</span>ON_SMARTPHONE<span class="sc">+</span>ASKS_QUESTIONS<span class="sc">+</span>LEAVES_EARLY<span class="sc">+</span>LATE_IN_CLASS, <span class="at">data =</span> moody[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>)],<span class="at">method =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb5-9"><a href="prpart.html#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="prpart.html#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Now lets import the rpart.plot library to use the rpart.plot() function.</span></span>
<span id="cb5-11"><a href="prpart.html#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb5-12"><a href="prpart.html#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="prpart.html#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use of the prp function  to visualize the decision tree.</span></span>
<span id="cb5-14"><a href="prpart.html#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="fu">prp</span>(tree)</span></code></pre></div>
<div class="figure">
<img src="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/img/modeling/prp1.svg" alt="" />
<p class="caption">Output Plot of <em>prp()</em> function</p>
</div>
<p>We can see that the output of the prp() function is a very minimalist tree, without any colors with minimum required information. There are other arguments that can be passed to the prp() function to increase the aesthetic look and the information provided. To learn those extra arguments visit this guide <a href="https://www.rdocumentation.org/packages/rpart.plot/versions/3.0.9/topics/prp">prp()</a></p>
<table>
<tbody>
<tr class="odd">
<td><strong>NOTE</strong>: In this chapter, from this point forward, the rpart.plots() generated in any example below will be shown as images, and also the code to generate those rpart.plots will be commented in the interactive code blocks. If you want to generate these plots yourself, please use a local Rstudio or R environment.</td>
</tr>
</tbody>
</table>
</div>
<div id="rpartcontrol" class="section level2 hasAnchor" number="16.3">
<h2><span class="header-section-number">16.3</span> Rpart Control<a href="prpart.html#rpartcontrol" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now let‚Äôs look at the rpart.control() function used to pass the control parameters to the control argument of the rpart() function.</p>
<ul>
<li><code>rpart.control( *minsplit*, *minbucket*, *cp*,...)</code></li>
<li><em>minsplit</em>: the minimum number of observations that must exist in a node in order for a split to be attempted. For example, minsplit=500 -&gt; the minimum number of observations in a node must be 500 or up, in order to perform the split at the testing condition.</li>
<li><em>minbucket</em>: minimum number of observations in any terminal(leaf) node. For example, minbucket=500 -&gt; the minimum number of observation in the terminal/leaf node of the trees must be 500 or above.<br />
</li>
<li><em>cp</em>: complexity parameter. Using this informs the program that any split which does not increase the accuracy of the fit by <em>cp</em>, will not be made in the tree.</li>
</ul>
<p>For more information of the other arguments of the <code>rpart.control()</code> function visit <a href="https://www.rdocumentation.org/packages/rpart/versions/4.1-15/topics/rpart.control">rpart.control</a></p>
<p>Note: The ratio of minsplt to minbucket is 3:1. Thus if only one of the minsplit/minbucket is provided the other value is set using the above ratio. Also if both values are provided, unless the values are not in the above ratio, the rpart.control() the resorts to the default value. Also note, the default value of cp is <code>0.01</code>.</p>
<p>Let look at few examples.</p>
<p>Suppose you want to set the control parameter minsplit=200.</p>
<p>dc_light_exercise_unnamed-chunk-126</p>
<pre><code>##             var    n
## 1         SCORE 1580
## 2         SCORE 1137
## 4         SCORE  469
## 5  LEAVES_EARLY  668
## 11        SCORE  218
## 3         SCORE  443</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/img/modeling/rcontrolsplit.svg" alt="" />
<p class="caption">Output tree plot of after setting minsplit=200 in rpart.control() function</p>
</div>
<p>We can see from the output of <code>tree$splits</code> and the tree plot, that at each split the total amount of observations are above 200. Also, in comparison to the tree without control, the tree with control has lower height, and lesser count of splits.</p>
<p>Now, lets set the minbucket parameter to 100, and see how that affects the tree parameters.</p>
<p>dc_light_exercise_unnamed-chunk-127</p>
<pre><code>##      var   n
## 8 &lt;leaf&gt; 149
## 9 &lt;leaf&gt; 320
## 5 &lt;leaf&gt; 668
## 6 &lt;leaf&gt; 240
## 7 &lt;leaf&gt; 203</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/img/modeling/rcontrolbucket.svg" alt="" />
<p class="caption">Output tree plot of after setting minbucket=100 in rpart.control() function</p>
</div>
<p>We can see for the output and the tree plot, that the count of observations in each leaf node is greater than 100. Also, the tree height has shortened, suggesting that the control method was able to shorten the tree size.</p>
<p>Lets now use the <code>cp</code> parameter and see its effect on the tree.</p>
<p>dc_light_exercise_unnamed-chunk-128</p>
<pre><code>##            CP nsplit  rel error     xerror        xstd
## 1 0.252561475      0 1.00000000 1.00000000 0.019790876
## 2 0.160860656      2 0.49487705 0.49487705 0.018762838
## 3 0.113729508      3 0.33401639 0.33709016 0.016536677
## 4 0.034323770      4 0.22028689 0.22643443 0.014126270
## 5 0.013319672      6 0.15163934 0.15778689 0.012079300
## 6 0.011782787      8 0.12500000 0.14549180 0.011647836
## 7 0.009221311     10 0.10143443 0.10963115 0.010233281
## 8 0.008709016     12 0.08299180 0.09528689 0.009585584
## 9 0.005000000     14 0.06557377 0.07274590 0.008437143</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/img/modeling/rcontrolcp.svg" alt="" />
<p class="caption">Output tree plot of after setting cp=0.005 in rpart.control() function</p>
</div>
<p>We can see for the output and the tree plot, that the tree size has increased, with increase in number of splits, and leaf nodes. Also we can see that the minimum CP value in the output is 0.005.</p>
<hr />
</div>
<div id="rpartpredict" class="section level2 hasAnchor" number="16.4">
<h2><span class="header-section-number">16.4</span> Prediction using rpart.<a href="prpart.html#rpartpredict" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have seen the process to create a decision tree and also plot it, we will like to use the output tree to predict the required attribute.</p>
<p>From the moody example, we are trying to predict the grade of students. Lets look at the <code>predict()</code> function to predict the outcomes.</p>
<ul>
<li><code>predict(*object*,*data*,*type*,...)</code>
<ul>
<li><em>object</em>: the generated tree from the rpart function.</li>
<li><em>data</em>: the data on which the prediction is to be performed.</li>
<li><em>type</em>: the type of prediction required. One of ‚Äúvector‚Äù, ‚Äúprob‚Äù, ‚Äúclass‚Äù or ‚Äúmatrix‚Äù.</li>
</ul></li>
</ul>
<p>Now lets use the predict function to predict the grades of students using the tree generated on the Moody dataset.</p>
<p>dc_light_exercise_unnamed-chunk-129</p>
<pre><code>## 1 2 3 4 5 6 
## D F C A C A 
## Levels: A B C D F</code></pre>
<p>Our prediction accuracy on the training data set is 93.73% and the error rate is 6.27%.This prediction accuracy calculated on the training dataset is called training accuracy. However, what we are really interested in is testing data accuracy. How can we make sure that our prediction model will achieve good testing data accuracy? It is not enough to see good training data accuracy. We need to do more work. It is called cross validation.Use only part of the training data for training the prediction model and the remaining part for testing. For that we would need to split the training data at least into two parts, Training and Testing and then repeat the training process on the training dataset and the prediction on testing dataset.</p>
<p>One way of doing this is to randomly assign data to either training or testing subset. We will look at a small example of splitting the complete dataset into training and testing dataset with a 70-30 ratio.</p>
<p>dc_light_exercise_unnamed-chunk-130</p>
<pre><code>## 1 2 3 4 5 6 
## D F C A C A 
## Levels: A B C D F</code></pre>
<pre><code>## [1] 93.73418</code></pre>
<hr />
</div>
<div id="splitdata" class="section level2 hasAnchor" number="16.5">
<h2><span class="header-section-number">16.5</span> Split the data yourself.<a href="prpart.html#splitdata" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>dc_light_exercise_unnamed-chunk-131</p>
<pre><code>## [1] 1580</code></pre>
<pre><code>## [1] 1125</code></pre>
<pre><code>## [1] 0.7120253</code></pre>
<pre><code>## [1] 455</code></pre>
<pre><code>## [1] 0.2879747</code></pre>
<p>As we can see we split the original data with 1580 rows into two dataset, training data with almost 70% of rows of the original, and testing data with almost 30% of the original. Notice that we used a random sampling of the data, and not just sequential, to avoid any unbalanced distribution of attributes.</p>
<p>Now, we looked at a method to split the dataset into training and testing data. But there is another type of splitting of the dataset which involves splitting the data into 3 parts namely, training, cross-validation and testing. We will look at the use of cross-validation and the process, in the next section <a href="prpart.html#crossvalidation">16.6</a>.</p>
<p>Typically, the ratio of train-validation-test is 60-20-20 or 50-25-25.</p>
<p>Before that lets look at a simple method to perform a 3 way split with ratio 60-20-20.</p>
<p>dc_light_exercise_unnamed-chunk-132</p>
<pre><code>## [1] 1580</code></pre>
<pre><code>## [1] 930</code></pre>
<pre><code>## [1] 0.5886076</code></pre>
<pre><code>## [1] 347</code></pre>
<pre><code>## [1] 0.2196203</code></pre>
<pre><code>## [1] 303</code></pre>
<pre><code>## [1] 0.1917722</code></pre>
<p>We can see that the dataset is split into 3 parts, with 60% in training data, 20% in validation data, and 20% in testing data.</p>
<p>In general, this process of repetitively using subsets of training data for training and testing is called cross validation.</p>
<hr />
</div>
<div id="crossvalidation" class="section level2 hasAnchor" number="16.6">
<h2><span class="header-section-number">16.6</span> Cross Validation<a href="prpart.html#crossvalidation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The goal of cross-validation is to test the model‚Äôs ability to predict new data that was not used in estimating/training it, in order to avoid problems like overfitting and selection bias, and to give an insight on how the model will generalize to an independent dataset(i.e., an unknown dataset).</p>
<p>Cross-validation also helps in selecting and fine-tuning the hyper-parameters of the models. In our case of the decision tree, the hyper parameters could be the control parameters that determine the size of the decision tree, which in-turn determines the accuracy of the tree.</p>
<p>One round of cross-validation involves partitioning data into complementary subsets, and then performing model training on one subset, and validating the results on the other subset. In most methods, multiple rounds of cross-validation are performed using different partitions in each round, and the validation results are combined (e.g.¬†averaged) over the rounds to give an estimate of the model‚Äôs predictive performance.</p>
<p>Another use of cross-validation is when you don‚Äôt have the test data, and hence, you don‚Äôt have a way to determine the true accuracy of the model. Because we cannot determine accuracy on the test dataset, we partition our training dataset into training and validation (testing). We train our model (rpart or lm) on the train partition and test on the validation partition. The accuracy on the validation data is called cross-validation accuracy, while that on the train data is called training accuracy.</p>
<p>Lets not dive too deep into the theory of this cross validation technique, but lets learn about the cross_validate() function, that helps us achieve this.</p>
<ul>
<li><code>cross_validate(*data*, *tree*, *n_iter*, *split_ratio*, *method*)</code>
<ul>
<li><em>data</em>: The dataset on which cross validation is to be performed.</li>
<li><em>tree</em>: The decision tree generated using rpart.</li>
<li><em>n_iter</em>: Number of iterations.</li>
<li><em>split_ratio</em>: The splitting ratio of the data into train data and validation data.</li>
<li><em>method</em>: Method of the prediction. ‚Äúclass‚Äù for classification.</li>
</ul></li>
</ul>
<p>The way the function works is as follows:</p>
<ul>
<li>It randomly partitions your data into training and validation.</li>
<li>It then constructs the following two decision trees on training partition:
<ul>
<li>The tree that you pass to the function.</li>
<li>The tree is constructed on all attributes as predictors and with no control parameters.
-It then determines the accuracy of the two trees on validation partition and returns you the accuracy values for both the trees.</li>
</ul></li>
</ul>
<p>The first column corresponds to the cross-validation accuracy on the tree that you pass; the second is the cross-validation accuracy on the tree without any control and all attributes.</p>
<p>The values in the first column(accuracy_subset) returned by cross-validation function are more important when it comes to detecting overfitting. If these values are much lower than the training accuracy you get, that means you are overfitting.</p>
<p>We would also want the values in accuracy_subset to be close to each other (in other words, have low variance). If the values are quite different from each other, that means your model (or tree) has a high variance which is not desired.</p>
<p>The second column(accuracy_all) tells you what happens if you construct a tree based on all attributes. If these values are larger than accuracy_subset, that means you are probably leaving out attributes from your tree that are relevant.</p>
<p>Each iteration of cross-validation creates a different random partition of train and validation, and so you have possibly different accuracy values for every iteration.</p>
<p>Let‚Äôs look at the cross_validate() function in action in the example below.</p>
<p>We will pass the tree with formula as <code>GRADE ~ SCORE+ON_SMARTPHONE+LEAVES_EARLY</code>, and control parameter, with <code>minsplit=100</code>.
And for cross_validate() function, we will use<code>n_iter=5, and split_raitio=0.7</code></p>
<p><em>NOTE</em>: Cross-Validation repository is already preloaded for the following interactive code block. Thus you can directly use the cross_validate() function in the following interactive code block. But if you wish to use the code_validate() function locally, please use</p>
<pre><code>install.packages(&quot;devtools&quot;) 
devtools::install_github(&quot;devanshagr/CrossValidation&quot;)
CrossValidation::cross_validate()</code></pre>
<div data-datacamp-exercise="" data-height="700" data-encoded="true">
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
</div>
<pre><code>## 1 2 3 4 5 6 
## D F B A B A 
## Levels: A B C D F</code></pre>
<pre><code>## [1] 0.9063291</code></pre>
<pre><code>## [[1]]
##   accuracy_subset accuracy_all
## 1       0.9135021    0.9261603
## 2       0.9050633    0.9345992
## 3       0.8924051    0.9324895
## 4       0.8797468    0.9324895
## 5       0.9261603    0.9324895
## 
## [[2]]
## [[2]]$average_accuracy_subset
## [1] 0.9033755
## 
## [[2]]$average_accuracy_all
## [1] 0.9316456
## 
## [[2]]$variance_accuracy_subset
## [1] 0.0003258025
## 
## [[2]]$variance_accuracy_all
## [1] 1.023696e-05</code></pre>
<p><em>NOTE</em>: If you encounter error while running the cross-validation function that said ‚Äúnew levels encountered‚Äù in test, make sure the dataset is imported again with read.csv() attribute <code>stringsAsFactors</code> as <code>TRUE or T</code>. For more information about the inner-working of the cross_validate() function visit <a href="https://github.com/devanshagr/CrossValidation/blob/master/R/cross_validation.R">cross_validate()</a></p>
<p>We can see in the output the Training accuracy, the table of cross-validation accuracy at each iteration for both the passed tree and the tree on all attribute and also their averages and variances.</p>
<p>Few Observation from the selected example above are:</p>
<ul>
<li>For the tree passed with selected attributes and some control parameters, the cross-validation accuracy‚Äôs (i.e.¬†accuracy values in the <code>accuracy_subset</code> column) are fairly high for all iterations and have very low variance.</li>
<li>They are close to the training accuracy which indicates we are not overfitting.</li>
<li>Observe that the accuracy at each iteration of the accuracy_subset and accuracy_all column are relatively, close but not exact, suggesting that there are more attributes or other control parameters that can be included to the passed tree, to further increase the accuracy, thus closing the gap.</li>
</ul>
<p>Thus using cross-validation we were able to figure out with certainty, that the passed tree, is not the best tree that can be created using the training data. Also, we saw whether the generated tree overfits the training data or not.</p>
<hr />
<p>EOC</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="P1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdemo.html"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
