# ðŸ”– Free Style: Prediction {#P1}

<script src="files/js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"> </script>

```{r ,include=FALSE}
tutorial::go_interactive(greedy = FALSE)

```

- **Lecture slides: **     <button class="btn btn-primary" data-toggle="collapse" data-target="#p12"> Prediction - Free Style </button> 
<div id="p12" class="collapse">
<embed src="https://docs.google.com/presentation/d/1pA0bzMGr_Tu2CXsgtT9Ks5apHqxWh8l1XXBVvwWr6zc/edit?usp=sharing" width="100%" height="500px"></embed>
</div>

## Snippet 1: Example of a simple freestyle prediction model

```{r,tut=TRUE,height=400}

test<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")

summary(test)

myprediction<-test
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
myprediction$Grade <-decision
error <- mean(test$Grade!= myprediction$Grade)
error
```

## Snippet 2: One-step crossvalidation

```{r,tut=TRUE,height=900}
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
summary(train)
#scramble the train frame
v<-sample(1:nrow(train))
v[1:5]
trainScrambled<-train[v, ]
#one step crossvalidation
trainSample<-trainScrambled[990:1000, ]
myprediction<-trainSample
#prediction model - free style
#How to test how good your model is?
#Crossvalidation:  Divide train data set into two disjoint subsets T (train) and train MINUS T, the complement of T. 
#You use T to derive your prediction model and the complement of T (train MINUS T) to validate (test it).
# We assume that you created prediction model looking just at the subset of training data T=trainScrambled[1:990,  ]. 

#Since for crossvalidation we train on a subset T of the training data set and validate (test) on the complement of T. 
#In this case T= trainScrambled[1:990,  ] and complement of T (to validate/test) is stored as trainSample.
#You can do it multiple times. And observe the error and its stability.
#You build your model using the decision vector.  Here is very SIMPLISTIC MODEL which is just illustration. Your model should have much better error and be more sophisticated. 


decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'

decision[myprediction$Score>60] <- 'C'

decision[myprediction$Score>70] <- 'B'

decision[myprediction$Score>80 ] <- 'A'

myprediction$Grade <-decision
error <- mean(trainSample$Grade!= myprediction$Grade)
error   
```

## Snippet 3: How to build a freestyle (your own code) prediction model?

```{r,tut=TRUE,height=500}
moody<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")

# How do we build a freestyle prediction model?  Definitely start with plots like the boxplot from the section 5 (data exploration).  But then follow up with exploratory queries as in the recent quizzes. Examples here use table()  functon and look for situations when one grade is absoutely dominant. This would be your prediction. Thus, the goal is to slice the data using subsetting in such a way that for each slice you get a clear "winner grade". Then combine these subset rules into decision vector - just as we did in snippet 14.1.

# Below some examples of such exploratory queries with clear grade winners.   (then we follow what we have now)

summary(moody)
table(moody$Grade)
table(moody[moody$Score>80,]$Grade)
table(moody[moody$Score>80 & moody$Major=='Psychology',]$Grade)
table(moody[moody$Score<40 & moody$Major=='Economics',]$Grade)
table(moody[moody$Score<40 & moody$Seniority=='Freshman',]$Grade)
```

## Snippet 4: Preparing submission.csv for Kaggle

```{r,tut=TRUE,height=500}
# Here you just need the test table (without grades) to apply your prediction model and calculate predicted grades. And submission data frame to fill it in with the predicted #grades

test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')

myprediction<-test
#Here is your model. I just show example of trivial prediction model
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
#Now make your submission file - it will have the IDs and now the predicted grades
submission$Grade<-decision
submission
# use write.csv(submission, 'submission.csv', row.name=FALSE) to store submission as csv file on your machine and subsequently submit it on Kaggle

```


