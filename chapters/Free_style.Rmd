# üîñ Prediction - I {#P1}

<script src="files/js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"> </script>

```{r ,include=FALSE}
tutorial::go_interactive(greedy = FALSE)

```

- **Lecture slides: **     <button class="btn btn-primary" data-toggle="collapse" data-target="#p12"> Prediction - Free Style </button> 
<div id="p12" class="collapse">
<embed src="https://docs.google.com/presentation/d/1pA0bzMGr_Tu2CXsgtT9Ks5apHqxWh8l1XXBVvwWr6zc/edit?usp=sharing" width="100%" height="500px"></embed>
</div>

Each prediction challenge is based on the training data generated synthetically with some embedded patterns. Students can either build their own prediction models from scratch (coding their own prediction models without using R libraries, ‚Äúfree style‚Äù) or utilize R libraries for a multitude of machine learning methods. These methods range from decision trees (rpart, recursive partitioning) through linear regression (lm), svm and even neural networks. Students test their prediction models on the testing data. We use Kaggle to automatically calculate the prediction errors and rank student solutions by prediction accuracy. Depending on the type of independent, target variable we use either prediction accuracy or MSE.

As data creators we know the method of data generation, therefore we can construct the perfect prediction model, Accuracy of the perfect prediction model provides a soft upper bound for prediction accuracy of all possible prediction models, created without knowing how data was generated. Thus, there is no general, absolute, notion of a ‚Äúgood‚Äù prediction model. It all depends on the data. Sometimes prediction accuracy of 60% is excellent. For other data sets, accuracy of 95% may not be good enough.

If the accuracy of a prediction model is near the accuracy of a perfect prediction model, such a model is definitely good.

```{r,tut=TRUE,height=400}

test<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")

summary(test)

myprediction<-test
decision <- rep('F',nrow(myprediction))
decision[myprediction$SCORE>40] <- 'D'
decision[myprediction$SCORE>60] <- 'C'
decision[myprediction$SCORE>70] <- 'B'
decision[myprediction$SCORE>80] <- 'A'
myprediction$Grade <-decision
error <- mean(test$Grade!= myprediction$Grade)
error

```