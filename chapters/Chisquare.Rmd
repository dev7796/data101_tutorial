# üîñ Chi Square Analysis {#chitest}

<script src="files/js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

```{r ,include=FALSE}
tutorial::go_interactive(greedy = FALSE)

```

The difference of means hypothesis testing is not the only hypothesis testing that we will cover in this textbook.  In our view, the Test of independence very much belongs to data 101 as well.

**Example:** We would like to test if student final grades are affected by their major?  The null hypothesis in this case is the hypothesis of independence. The final grades are independent from major. The alternative hypothesis is that final grades are affected by major. 

Notice that we do not specify how the grades are affected by students' majors.  Do CS students get better grades than psychology  majors? Do economics majors get lower grades than Statistics majors?  We do not care about this. We are only testing here whether there is a relationship between major and grade distributions.

We will follow our permutation test path which we took in the previous section. We will describe the permutation test which will scramble our data randomly in such a way that any relationship between grades and major  (if it ever existed) will be broken. We will run a permutation test a large number of times - possibly tens of thousands and see how likely it is to randomly obtain the observed result. But what is the observed result?

The observed result in this case is calculated by so called chi-square statistic which is calculated on the contingency table, ```table(moody$Grade, moody$Major)```

**OBSERVED CONTINGENCY TABLE**
<table>
<tr>
<td>Grade/Major</td>
<td>CS</td>
<td>Economics</td>
<td>Psychology</td>
<td>Statistics</td>
</tr>

<tr>
<td>A</td>
<td>46</td>
<td>54</td>
<td>69</td>
<td>42</td>
</tr>

<tr>
<td>B</td>
<td>46</td>
<td>12</td>
<td>2</td>
<td>35</td>
</tr>

<tr>
<td>C</td>
<td>51</td>
<td>33</td>
<td>30</td>
<td>34</td>
</tr>

<tr>
<td>D</td>
<td>41</td>
<td>37</td>
<td>29</td>
<td>34</td>
</tr>

<tr>
<td>F</td>
<td>108</td>
<td>99</td>
<td>99</td>
<td>99</td>
</tr>

</table>


The expected table (that is table where both distributions are independent) would result in equal distribution of grades for each of the majors.  Notice that we 1000 students in the data set the expected table (i.e. table which have grades completely independent from majors) would  have the same distribution of grades for each major that over all students - which is shown by the **TOTAL** column.

**EXPECTED CONTINGENCY TABLE**
<table>
<tr>
<td>Grade/Major</td>
<td>CS</td>
<td>Economics</td>
<td>Psychology</td>
<td>Statistics</td>
<td>TOTAL</td>
</tr>

<tr>
<td>A</td>
<td>61.32</td>
<td>49.58</td>
<td>48.1</td>
<td>51.24</td>
<td>211</td>
</tr>

<tr>
<td>B</td>
<td>27.74</td>
<td>22.42</td>
<td>21.75</td>
<td>23.18</td>
<td>95</td>
</tr>

<tr>
<td>C</td>
<td>43.31</td>
<td>34.93</td>
<td>33.9</td>
<td>36.11</td>
<td>148</td>
</tr>

<tr>
<td>D</td>
<td>41.17</td>
<td>33.28</td>
<td>32.29</td>
<td>34.40</td>
<td>141</td>
</tr>

<tr>
<td>F</td>
<td>118.26</td>
<td>95.58</td>
<td>92.75</td>
<td>98.82</td>
<td>405</td>
</tr>

<tr>
<td>TOTAL</td>
<td>292</td>
<td>236</td>
<td>229</td>
<td>244</td>
<td>1000</td>
</tr>
</table>

We kept fractions - although these are number of students - therefore would have to be rounded up to integers 

The chi-square formula calculates the **‚Äúdistance‚Äù** between the observed contingency table and the expected contingency table.

**‚àë(i‚ãÖj)(O‚àíE)2E**

```
where:
O = observed values
E = expected values
i = the number of rows in the table
j = the number of columns in the table
For the two tables above the 
```

\begin{equation}

\sum \frac{(O_i - E_i)^2}{E_i}  = 60.03\\
\text{where, X is set of numbers, $\mu$ is average of set of numbers, }\\ \text{ N is size of the set, $\sigma$ is standard deviation}


\end{equation}

**‚àë(i‚ãÖj)(O‚àíE)2E = 60.03**

To evaluate how far off is this result assuming that Grades are independent from Major, we run a permutation test which scrambles Grades and Majors randomly and every time computes the chi-square formula with the new observed table (the expected table is always the same).  Then, we see how many times out of, say 10,000 iterations of permutation test we obtain a result larger than the observed result of 60.03? This is the p-value. 

Permutation test for independence hypothesis gives us again a better feeling about the impact of randomness and whether the observed chi-square result for **‚Äúsimilarity‚Äù** of grade distributions for different majors can be obtained randomly. 

In the following snippet we run the chisq test which is based on the so-called chi square distribution, you can learn more about it in a statistics class.  Here we just simply show you a function which can calculate p-value, just like the z-test function does. 

Permutation tests in both cases of difference of means and independence hypotheses give a better intuitive sense of how we answer the question - can the observed result be obtained randomly?  Again no need to learn statistical foundations yet to get a grip of how we are addressing the randomness trap. 

Notice that the independence test is looking globally at two vectors and whether one affects another. If we wanted to be more specific and know if psychology majors are more likely to get an A than CS majors, we can frame this as a difference of means hypothesis. Testing this hypothesis will be using the difference of means of frequencies of A‚Äôs among CS majors and psychology majors.  This could be done again by permutation test in section 7 or the z-test. 


## Snippet 1

```{r,tut=TRUE,height=300}
Expected <-matrix(c(200,420,180, 40,120,40), nrow=3, ncol=2)
Observed<-matrix(c(200,420,180,35,120,45), nrow=3, ncol=2)
Expected
Observed
chisq.test(Observed)
```

## Snippet 2

```{r,tut=TRUE,ex="chisquarefunction",type="pre-exercise-code"}
library(dplyr)
options(warn=-1)
chi_test <- function(data,col1,col2,iter) {
  
  df <- data.frame(data)
  vals<- unique(df[[col2]])
  no_rows <- nrow(df)
  dt <- table(df[[col1]], df[[col2]])
  res <- chisq.test(dt)
  real_ans <- res$statistic
  p_value <- res$p.value
  ans_vec <- vector()
  for (x in 1:iter){

    new_data <- sample(x=vals,size=no_rows,replace = TRUE)

    dt_new <- table(df[[col1]], new_data)

    res_new <- chisq.test(dt_new)

    ans_vec <- append(ans_vec,res_new$statistic)
  }
  hist(ans_vec,main="Permutation Test for Chi-Square",xlab="Chi-Square Values",breaks = 100)
  print(real_ans)
  abline(v=real_ans,col="blue",lwd=2)
  return (p_value)
}

```


```{r,tut=TRUE,ex="chisquarefunction",type="sample-code",height=500}

d<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
head(d)

chi_test(d,"Major","Grade",1000)

```

## Snippet 3

```{r,tut=TRUE,height=300}
moody<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/moody2022_new.csv")
moody$IN<-'Out_Slice'
moody[moody$DOZES_OFF=='never' & moody$TEXTING_IN_CLASS=='always', ]$IN<-'In_Slice'
d<-table(moody$GRADE, moody$IN)
d
chisq.test(d)
```

## Snippet 4


```{r,tut=TRUE,height=300}
movies<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/Movies2022F-4.csv")
data<-table(movies$content, movies$genre)
chisq.test(data)
```

## Additional Reference

<button class="btn btn-primary" data-toggle="collapse" data-target="#CS12">Chi Square</button> 

<button class="btn btn-primary" data-toggle="collapse" data-target="#KH13">Khan Academy Video</button>

<div id="CS12" class="collapse">
<embed src="https://docs.google.com/presentation/d/1h-h2S5lW6ReFwdeJKNflPpE0iCjoS08T0mpgSLiFv88/edit?usp=sharing" width="100%" height="500px"></embed>
</div>

<div id="KH13" class="collapse">https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic
</div>
